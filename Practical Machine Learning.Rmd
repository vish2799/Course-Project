---
title: "Practical Machine Learning"
author: "Vishakha Sawant"
date: "11/08/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
##Data Availibity
#Training Data: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
#Test data : https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv
#The Training Data will be used to develop algorithm and Test Data to make our final predictions..

##Required Packages
#Installing and Loading Packages.
install.packages('caret')
install.packages('lattice')
install.packages('randomForest')
install.packages('rpart')
install.packages('rpart.plot')
install.packages('RColorBrewer')
install.packages('rattle')
install.packages('ggplot2')
install.packages('e1071')
library(e1071)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(ggplot2)

#Getting Working Directory
getwd()

#Loading Training and Test Datasets
train = read.csv('pml-training.csv',na.strings=c('','NA'))
test = read.csv('pml-testing.csv',na.strings=c('','NA'))

#exploring data
head(train)
tail(train)

##Data Set Partition
#First, we split the training data set into two subsamples, the 70% will be used as training set and remaining 30% will be used as testing set.

inTrain <- createDataPartition(train$classe, p = 0.7, list = FALSE)
train1 <- train[inTrain, ]
train2 <- train[-inTrain, ]

##Performing Data Cleaning.
#removing near-zero variance predictors
nZV <- nearZeroVar(train)
train1 <- train1[, -nZV]
train2 <- train2[, -nZV]
#removing predictors with NA values
train1 <- train1[, colSums(is.na(train1)) == 0]
train2 <- train2[, colSums(is.na(train2)) == 0]
#removing 6 columns unfit for prediction 
train1 <- train1[, -(1:5)]
train2 <- train[, -(1:5)]

#Model Building.
#We chose to fit a random forest model. 
#The cross-validation is set to draw a subset of the data three different times.

model1 <- train(classe ~., method = "rf", data = train1, verbose = TRUE, trControl = trainControl(method="cv"), number = 3)

#prediction using model1 on training set 1and training set 2
prediction1 <- predict(model1, train1)
prediction2 <- predict(model1, train2)

#Confusion Matrix
confusionMatrix(prediction1, as.factor(train1$classe))
confusionMatrix(prediction2, as.factor(train2$classe))

Results:
Confusion Matrix and Statistics
          Reference
Prediction    A    B    C    D    E
         A 3906    0    0    0    0
         B    0 2658    0    0    0
         C    0    0 2396    0    0
         D    0    0    0 2252    0
         E    0    0    0    0 2525
Overall Statistics
                                     
               Accuracy : 1          
                 95% CI : (0.9997, 1)
    No Information Rate : 0.2843     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
                                     
 Mcnemar's Test P-Value : NA         
Statistics by Class:
                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2843   0.1935   0.1744   0.1639   0.1838
Detection Prevalence   0.2843   0.1935   0.1744   0.1639   0.1838
Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000
Confusion Matrix and Statistics
          Reference
Prediction    A    B    C    D    E
         A 5580   10    0    0    0
         B    0 3787    1    0    2
         C    0    0 3421    3    0
         D    0    0    0 3213    0
         E    0    0    0    0 3605
Overall Statistics
                                          
               Accuracy : 0.9992          
                 95% CI : (0.9987, 0.9995)
    No Information Rate : 0.2844          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.999           
                                          
 Mcnemar's Test P-Value : NA              
Statistics by Class:
                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9974   0.9997   0.9991   0.9994
Specificity            0.9993   0.9998   0.9998   1.0000   1.0000
Pos Pred Value         0.9982   0.9992   0.9991   1.0000   1.0000
Neg Pred Value         1.0000   0.9994   0.9999   0.9998   0.9999
Prevalence             0.2844   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2844   0.1930   0.1743   0.1637   0.1837
Detection Prevalence   0.2849   0.1932   0.1745   0.1637   0.1837
Balanced Accuracy      0.9996   0.9986   0.9998   0.9995   0.9997

#we get almost 99% accuracy that is a very high accuracy so we didnt actually overfit the model and also we can say that out of sample error is about 1%.

##Testing Model
#were testing our model using testing set.
test <- test[, colSums(is.na(test)) == 0]
test <- test[, -(1:5)]
nzvt <- nearZeroVar(test)
test <- test[, -nzvt]
#Prediction using model1 on testing dataset
prediction <- predict(model1, test)
prediction

Output:
 [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E
```

